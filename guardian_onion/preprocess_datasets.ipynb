{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Imports for Spacy\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "\n",
    "#datasets\n",
    "from standardize_datasets import get_merge_dataset\n",
    "from standardize_datasets import standardize_without_theme\n",
    "from standardize_datasets import clean_unicode\n",
    "from standardize_datasets import remove_punctuation\n",
    "from standardize_datasets import get_clean_dataset\n",
    "from standardize_datasets import preprocess\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def remove_stopwords_and_lemmatize_spacy(doc):\n",
    "    return (w.lemma_ for w in doc if not w.is_stop)\n",
    "\n",
    "def remove_blank_space(sentence):\n",
    "    return (word for word in sentence if word != ' ')\n",
    "\n",
    "def to_lower(word):\n",
    "    return word.lower()\n",
    "\n",
    "def preprocess(list_of_sentences):\n",
    "    docs = nlp.pipe(list_of_sentences, batch_size=1000, disable=['parser', 'ner'])\n",
    "    lemmatized_sentences = (remove_stopwords_and_lemmatize_spacy(doc) for doc in docs)\n",
    "    without_blank_spaces = (remove_blank_space(sentence) for sentence in lemmatized_sentences)\n",
    "    lowercased_words = (to_lower(word) for sentence in without_blank_spaces for word in sentence)\n",
    "    return lowercased_words \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_generator(sentences, n_process=4):\n",
    "    docs = nlp.pipe(sentences, n_process=n_process, batch_size=100, disable=['parser', 'ner'])\n",
    "    lemmatized_sentences = ([w.lemma_ for w in doc if not w.is_stop] for doc in docs)\n",
    "    without_blank_spaces = ([word for word in sentence if word != ' '] for sentence in lemmatized_sentences)\n",
    "    lowercased_words = ([word.lower() for word in sentence] for sentence in without_blank_spaces)\n",
    "    return lowercased_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only one use necessary\n",
    "def create_and_save_clean_dataset():\n",
    "    df = get_merge_dataset()\n",
    "    df['article'] = df['article'].apply(clean_unicode)\n",
    "    df['article'] = df['article'].apply(remove_punctuation)\n",
    "    df.to_csv('data/satire_dataset.csv', index=False)\n",
    "create_and_save_clean_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_clean_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['article'] = preprocess(df['article'], n_process=8)\n",
    "df.to_csv('data/preprocessed_satire_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f['article'] = preprocess(df['article'], n_process=1)\n",
    "df.to_csv('data/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_true = pd.read_csv('data/preprocessed_satire_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['australia', 'claw', 'way', 'rugby', 'league', 'tree', 'utterly', 'dominant', 'demolition', 'kiwis', 'record', 'break', 'historic', 'embarrassing', 'choose', 'adjective', 'depend', 'national', 'persuasion', 'wherever', 'come', 'fact', 'simple', 'kangaroos', 'crush', 'new', 'zealand', '34', '8', 'anfield', 'sunday', 'regain', 'four', 'nations', 'title', 'lose', 'opponent', 'year', 'ago', 'it', 'result', 'emphasise', 'gulf', 'australia', 'enjoy', 'rest', 'rugby', 'league', 'world', 'underline', 'sport', 's', 'big', 'problem', 'international', 'level', 'competitiveness', 'once', 'big', 'international', 'game', 'shape', 'england', 'new', 'zealand', 'australia', 'now', 'kangaroos', 'reign', 'supreme', 'australia', 'beat', 'kiwis', 'time', 'year', 'victory', 'completely', 'convince', 'england', 'defeat', 'australia', '21', 'year', 'decade', 'great', 'britain', 'while', 'like', 'scotland', 'samoa', 'fiji', 'undoubtedly', 'improve', 'green', 'gold', 'remain', 'eerily', 'distant', 'it', 'ominous', 'sign', 'year', 'world', 'cup', 'hold', 'country', 'the', 'final', 'half', 'time', 'new', 'zealand', 'stare', 'barrel', '24', '0', 'scoreline', 'their', 'brittle', 'defence', 'concede', 'try', 'half', 'incredibly', 'soft', 'australia', 's', 'opener', 'scrum', '10', 'metre', 'try', 'line', 'darius', 'boyd', 'feed', 'blake', 'ferguson', 'like', 'training', 'australia', 'wrong', 'new', 'zealand', 'architect', 'downfall', 'the', 'kangaroos', 'near', 'perfect', 'punish', 'mistake', 'big', 'small', 'kiwis', 'and', 'man', 'land', 'long', 'white', 'cloud', 'generous', 'mood', 'gift', 'aussies', 'plenty', 'possession', 'scoring', 'chance', 'there', 'seven', 'error', '20', 'minute', 'the', 'thing', 'australia', 'need', 'help', 'hand', 'time', 'time', 'get', 'in', 'second', 'half', 'new', 'zealand', 'dig', 'jordan', 'kahu', 'bag', 'try', 'kahu', 'stand', 'injure', 'roger', 'tuivasa', 'sheck', 'fist', 'time', 'jumper', 'but', 'australia', '28', '0', 'lead', 'expect', 'win', 'game', 'serious', 'question', 'need', 'ask', 'david', 'kidwell', 's', 'tenure', 'new', 'zealand', 'coach', 'he', 'get', 'job', 'right', 'four', 'nations', 'tournament', 'win', 'game', 'they', 'scrape', 'england', 'hold', 'draw', 'scotland', 'result', 'history', 'book', 'you', 't', 'kidwell', 'replace', '12', 'month', 'world', 'cup', 'strange', 'thing', 'happen', 'the', 'kiwis', 'surrender', 'four', 'nations', 'title', 'no1', 'world', 'rank', 'meekly', 'the', 'decision', 'appoint', 'rookie', 'coach', 'lead', 'nrl', 'super', 'league', 'grade', 'team', 'curious', 'yes', 'kidwell', 'learn', 'like', 'craig', 'bellamy', 'stephen', 'kearney', 'step', 'test', 'level', 'huge', 'new', 'zealand', 'well', 'especially', 'key', 'player', 'return', 'injury', 'but', 'pride', 'take', 'big', 'hit', 'anfield', 'a', 'period', 'introspection', 'need', 'australia', 'hark', 'golden', 'age', 'day', 'lewis', 'sterling', 'langer', 'johns', 'tallis', 'lockyer', 'rest', 'this', 'team', 'frighteningly', 'good', 'play', 'power', 'execution', 'breathtake', 'when', 'perform', 'like', 'opponent', 'error', 'prone', 'outcome', 'sadly', '2017', 'world', 'cup', 'look', 'like', 'foregone', 'conclusion']\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_true['article'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
